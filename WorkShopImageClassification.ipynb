{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/teerasitk/thaicomRemoteSensing/blob/main/WorkShopImageClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gS382llmquMY"
      },
      "source": [
        "# Work with Google Earth Engine"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbvyhFI_qxug"
      },
      "source": [
        " ### 1. Load library and initialize Google Earth Engine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_9GqVadke0hV"
      },
      "outputs": [],
      "source": [
        "import ee\n",
        "ee.Authenticate()\n",
        "ee.Initialize()\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PluHzKgcq2Or"
      },
      "source": [
        "### 2. Build the display function for land cover map and image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U91OTpAtf-0k"
      },
      "outputs": [],
      "source": [
        "import folium\n",
        "def showLC(image, lc_label, aoi, num_classes, palette=None, zoom=15):\n",
        "  xc, yc =  aoi.centroid().getInfo()['coordinates']\n",
        "  aoi_map = folium.Map(location=[yc, xc], zoom_start=zoom)\n",
        "  basemaps = {'Google Maps': folium.TileLayer(\n",
        "    tiles = 'https://mt1.google.com/vt/lyrs=m&x={x}&y={y}&z={z}',  #google map service site\n",
        "    attr = 'Google',  \n",
        "    name = 'Google Maps', \n",
        "    overlay = True,\n",
        "    control=True)} # tell folium that the base map is the google map. \n",
        "  basemaps['Google Maps'].add_to(aoi_map) # add google earth data into ku_map\n",
        "  im_clib = image.clip(aoi)\n",
        "  if  palette is None:\n",
        "     palette = ['006400' ,'ffbb22', 'ffff4c', 'f096ff', 'fa0000', 'b4b4b4',\n",
        "                'f0f0f0', '0064c8', '0096a0', '00cf75', 'fae6a0']\n",
        "  viz_params = {'bands':[lc_label], \n",
        "                'min': 0, \n",
        "                'palette': palette,\n",
        "                'max':num_classes} \n",
        "  map_obj = im_clib.getMapId(viz_params) # convert image into map object\n",
        "\n",
        "  folium.TileLayer(\n",
        "      tiles=map_obj ['tile_fetcher'].url_format, #item where the image is linked to\n",
        "      overlay=True,\n",
        "      attr='Original Image',\n",
        "      name=f'False Color Composite',\n",
        "    ).add_to(aoi_map)\n",
        "  return aoi_map\n",
        "\n",
        "def showImageOnMap(image, bands, aoi, min_val, max_val, zoom=15):\n",
        "  xc, yc =  aoi.centroid().getInfo()['coordinates']\n",
        "  aoi_map = folium.Map(location=[yc, xc], zoom_start=zoom)\n",
        "  basemaps = {'Google Maps': folium.TileLayer(\n",
        "    tiles = 'https://mt1.google.com/vt/lyrs=m&x={x}&y={y}&z={z}',  #google map service site\n",
        "    attr = 'Google',  \n",
        "    name = 'Google Maps', \n",
        "    overlay = True,\n",
        "    control=True)} # tell folium that the base map is the google map. \n",
        "  basemaps['Google Maps'].add_to(aoi_map) # add google earth data into ku_map\n",
        "  im_clib = image.clip(aoi)\n",
        "  viz_params = {'bands':bands, 'min': min_val, \n",
        "                'max': max_val} \n",
        "  map_obj = im_clib.getMapId(viz_params) # convert image into map object\n",
        "\n",
        "  folium.TileLayer(\n",
        "      tiles=map_obj ['tile_fetcher'].url_format, #item where the image is linked to\n",
        "      overlay=True,\n",
        "      attr='Original Image',\n",
        "      name=f'False Color Composite',\n",
        "    ).add_to(aoi_map)\n",
        "  return aoi_map\n",
        "def getNewBandNames(prefix, num):\n",
        "  return [f\"{prefix}{k}\" for k in range(num)]\n",
        "def normalizeAllBand(image, aoi):\n",
        "  img_band_names = image.bandNames().getInfo()\n",
        "  imout = None \n",
        "  for band in img_band_names:\n",
        "    imb = image.select(band)\n",
        "    min_max = imb.reduceRegion(ee.Reducer.percentile([2,98]),\n",
        "                               geometry=aoi)#.getIngo()\n",
        "    print(min_max.getInfo())\n",
        "    imb = imb.unitScale(min_max.get(band+'_p2'), min_max.get(band+'_p98'))\n",
        "    if imout is None:\n",
        "      imout = imb\n",
        "    else:\n",
        "      imout = imout.addBands(imb)\n",
        "  return imout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrkOKfb1zatG"
      },
      "source": [
        "### 3. Set the area of interest (AOI)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_3YfRcWMe77C"
      },
      "outputs": [],
      "source": [
        "aoi = ee.Geometry.Polygon([ [ 99.776796700071003, 17.064532089073847 ],\n",
        "                           [ 99.821638573909041, 17.079199991731151 ],\n",
        "                           [ 99.870671277077747, 17.06620842080611 ],\n",
        "                           [ 99.86710907214669, 16.987211287923198 ],\n",
        "                           [ 99.774282202472605, 16.983858624458673 ], \n",
        "                           [ 99.776796700071003, 17.064532089073847 ] ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJLii_CBzfPo"
      },
      "source": [
        "### 4. Load a single date Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_MhkmtPfe9jr"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime \n",
        "img = ee.ImageCollection('COPERNICUS/S2_SR')\n",
        "img = img.filter(ee.Filter.lt(\"CLOUDY_PIXEL_PERCENTAGE\", 10)).filterDate('2019-11-01','2019-12-01')\n",
        "img = img.select(\"B.*\")\n",
        "img = img.filterBounds(aoi).first()\n",
        "date = img.getInfo()['properties'][\"system:time_start\"]\n",
        "date = date_time_obj = datetime.fromtimestamp(date/1000.0) \n",
        "datetxt = date.strftime('%Y-%m-%d')\n",
        "print(f\"Image was captured on {datetxt}\")\n",
        "img = img.multiply(0.0001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oocXcW3mz6XI"
      },
      "source": [
        "### 5. Display an image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bHr5_GVCgyzS"
      },
      "outputs": [],
      "source": [
        "im_map = showImageOnMap(img, [\"B8\",\"B4\", \"B3\"],aoi, min_val=0, max_val=0.5, zoom=14)\n",
        "im_map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_C-k7-0lz_Tx"
      },
      "source": [
        "### 6. Load Ground data from ESA WorldCover 10m v100 dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DHF-2QGmfAJs"
      },
      "outputs": [],
      "source": [
        "dataset = ee.ImageCollection(\"ESA/WorldCover/v100\").first()\n",
        "date = dataset .getInfo()['properties'][\"system:time_start\"]\n",
        "date = date_time_obj = datetime.fromtimestamp(date/1000.0) \n",
        "datetxt = date.strftime('%Y-%m-%d')\n",
        "print(f\"Dataset was creted on {datetxt}\")\n",
        "remap_values = ee.List([0, 1,1, 2, 3, 4, 4, 5, 4, 4, 4])\n",
        "label = \"landcover\"\n",
        "legend = ['Trees', 'Shrubland-Grassland', 'Cropland', 'Built-up', 'Barren / sparse vegetation', 'Open water']\n",
        "palette = ['006400' ,'00FA00', 'ffff4c', 'fa0000', 'f000f0', '0000fa']\n",
        "class_values = ee.List([10, 20, 30, 40, 50, 60, 70, 80, 90, 95, 100])\n",
        "dataset = dataset.remap(class_values, remap_values).rename(label).toByte()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fKp1yTd0Tyu"
      },
      "source": [
        "### 7. Display the ground data where\n",
        "- Dark Green: Trees\n",
        "- Light Green: Shrubland and Grassland\n",
        "- Yellow: Cropland\n",
        "- Red: Built-up\n",
        "- Purple: Barren / sparse vegetation\n",
        "- Blue: Open Water\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WR8fnuWBhMJN"
      },
      "outputs": [],
      "source": [
        "lc_map = showLC(dataset, label, aoi, 5, zoom=14, palette=palette)\n",
        "lc_map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjtoqC8G01sF"
      },
      "source": [
        "### 8. Take 100 samples per class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9axHI_7XfDFe"
      },
      "outputs": [],
      "source": [
        "sample = img.addBands(dataset).stratifiedSample(numPoints=100, \n",
        "                                                classBand=label,\n",
        "                                                region=aoi,\n",
        "                                                scale=10,\n",
        "                                                geometries=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlzYKoV608fr"
      },
      "source": [
        "### 9. Check how many samples that we can actually collected"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fYBbZtMRopmc"
      },
      "outputs": [],
      "source": [
        "for cl, name in enumerate(legend):\n",
        "  num = sample.filter(f'landcover=={cl}').aggregate_count(\"landcover\").getInfo()\n",
        "  print(f\"Sample Class {name}: {num}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_ABJ6I31PPj"
      },
      "source": [
        "### 10. Make 70% Train and 30% Test Samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FTKojAOwfEb2"
      },
      "outputs": [],
      "source": [
        "sample = sample.randomColumn()\n",
        "trainingSample = sample.filter('random <= 0.7')\n",
        "validationSample = sample.filter('random > 0.7')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6oyPrUT1aU_"
      },
      "source": [
        "### 11. Build Support Vector Machine with RBF kernel function with $\\gamma=5$ \n",
        "\n",
        "$\\phi(u,v)= e^{-\\gamma|u-v|^2}$\n",
        "\n",
        "and penalty $C=100$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oc8fIKNHilFV"
      },
      "outputs": [],
      "source": [
        "trainedClassifier = ee.Classifier.libsvm(kernelType=\"RBF\",gamma=5,cost=100)\n",
        "trainedClassifier = trainedClassifier.train(features=trainingSample, \n",
        "                                            classProperty=label,\n",
        "                                            inputProperties=img.bandNames())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CROpbkBl18Ne"
      },
      "source": [
        "### 12. Check on the description of the classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_SYlm_RYiy6-"
      },
      "outputs": [],
      "source": [
        "trainedClassifier.explain().getInfo()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1TtQtg22DiT"
      },
      "source": [
        "### 13. Obtain confusion matrix on both train and validation samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D8v0SgQriz0W"
      },
      "outputs": [],
      "source": [
        "train_conf_mat = np.array(trainedClassifier.confusionMatrix().getInfo())\n",
        "validationResult = validationSample.classify(trainedClassifier)\n",
        "validation_conf_mat = np.array(validationResult.errorMatrix(label, 'classification').getInfo())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confusion matrix for Train Samples"
      ],
      "metadata": {
        "id": "burdxdRnWURr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ll6wHsvw2_GN",
        "outputId": "1c3dfc1b-b33c-4e32-f683-6b7db9b747b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[52  7  3  2  3  0]\n",
            " [ 6 51  7  0  6  0]\n",
            " [ 6  1 56  2  7  0]\n",
            " [ 5  0  0 65  8  0]\n",
            " [ 7  7  8  7 44  0]\n",
            " [ 0  0  0  0  2 68]]\n"
          ]
        }
      ],
      "source": [
        "print(train_conf_mat)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confusion matrix for validation Samples"
      ],
      "metadata": {
        "id": "Ce9vbznNWZTO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A9YnOWeb3BeX"
      },
      "outputs": [],
      "source": [
        "print(validation_conf_mat)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVzzQNKV2eFQ"
      },
      "source": [
        "#### 12.1 Compute OA, Kappa, and Producers and Users' accuracies on Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dxENuL8z2N73"
      },
      "outputs": [],
      "source": [
        "def evaluteReport(conf_mat, legend=None):\n",
        "  diag_conf_mat = np.diag(conf_mat)\n",
        "  N = conf_mat.sum()\n",
        "  N_ref = conf_mat.sum(0)\n",
        "  N_map  = conf_mat.sum(1)\n",
        "  pc = diag_conf_mat.sum()/ N\n",
        "  ua = diag_conf_mat/ N_map\n",
        "  pa = diag_conf_mat/ N_ref\n",
        "  pe = (N_map * N_ref).sum() / (N**2)\n",
        "  kappa = (pc - pe)/(1-pe)\n",
        "  print(f\"OA: {pc:0.3f} with Kappa: {kappa:0.3f}\")\n",
        "  if legend is None:\n",
        "    legend = np.arange(conf_mat.shape[0])\n",
        "  for k, name in enumerate(legend):\n",
        "    print(f\"PA[{name}]: {pa[k]:0.3f}, UA[{name}]: {ua[k]:0.3f}\")\n",
        "  return pc, kappa, ua, pa"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate on train samples"
      ],
      "metadata": {
        "id": "9Hwp01y9WivS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kw28d3-u2MB2"
      },
      "outputs": [],
      "source": [
        "_ = evaluteReport(train_conf_mat, legend)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iw5Y6xhp24PD"
      },
      "source": [
        "#### 12.2 Compute OA, Kappa, and Producers and Users' accuracies on Validation Samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6XDdCCzuoX2Z"
      },
      "outputs": [],
      "source": [
        "_ = evaluteReport(validation_conf_mat, legend)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6MAzv4N3_eb"
      },
      "source": [
        "By comparing the results from train and validation samples, we observed that accuracies on both samples are quite similar excepts on Barren / sparse vegetatio Class. \n",
        "\n",
        "However, the validation accuracies seems to be smaller than those on the train samples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2_2ALgv3Syp"
      },
      "source": [
        "### 13. Display the resulting land cover map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UHy72prpnF0c"
      },
      "outputs": [],
      "source": [
        "imgClassified = img.classify(trainedClassifier);\n",
        "lc_map = showLC(imgClassified, \"classification\", aoi, 5, zoom=14, palette=palette)\n",
        "lc_map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8Y_cakQ4eKa"
      },
      "source": [
        "### 14. Let evaluate on the test samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c_39r4eRnZXq"
      },
      "outputs": [],
      "source": [
        "test_sample = img.addBands(dataset).sample(numPixels=1000,    # get another 1000 test samples\n",
        "                                           region=aoi,\n",
        "                                           scale=10,\n",
        "                                           geometries=True)\n",
        "for cl, name in enumerate(legend):\n",
        "  num = test_sample.filter(f'landcover=={cl}').aggregate_count(\"landcover\").getInfo()\n",
        "  print(f\"Sample Class {name}: {num}\") # how many samples per class\n",
        "test_result = test_sample.classify(trainedClassifier)\n",
        "test_conf_mat = np.array(test_result.errorMatrix(label, 'classification').getInfo())\n",
        "_ = evaluteReport(test_conf_mat, legend)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeDOXArK5ZC_"
      },
      "source": [
        "From the test and validation results, we found that the accuracies on the test samples are low.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_s7UekE5nwf"
      },
      "source": [
        "# Assignment 1\n",
        "Let us try to improve the accuracies by increasing the number of samples to 1,000 per class.\n",
        "\n",
        "Report on Train, Validation and Test Accuracies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bt01k7Ch55qa"
      },
      "outputs": [],
      "source": [
        "# You code is here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTjaKlcN58Ub"
      },
      "source": [
        "## Result for 1,000 samples:__________. \n",
        "What is your obsevation after increasing the number of samples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBdbOHHa6g3O"
      },
      "source": [
        "# Assignment 2\n",
        "\n",
        "Maybe the poor accuracies on the test samples are due to the fact that we employed the inferior classifier. In this examples, we will use a more sophisticated classifier, namely, the Random Forest. To initialize the Random Forest we will write\n",
        "stateOfTheArtClassifier = ee.Classifier.smileRandomForest(100, maxNodes=1024). \n",
        "Try the new classifier with 1000 samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "juUp6ym57JYs"
      },
      "outputs": [],
      "source": [
        "# You code is here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Goj3pp97I0Q"
      },
      "source": [
        "Report yor results on train, validation, and test samples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HaaCDx848lAK"
      },
      "source": [
        "# Assignment 3\n",
        "\n",
        "From the results on Assignment 2, you will see that there are big gaps between train and validation accuracies. This phenomenal is called **Overfitting** problem. The remedy to this problem can be one of combination of these strategies.\n",
        "\n",
        "1. Increse the number of samples\n",
        "2. Reduce the number of features\n",
        "3. Find better feature vectors. \n",
        "\n",
        "In this assignment, we will first try to reduce the number of features\n",
        "Here, we will use only \"B2\", \"B3\", \"B4\", and \"B8\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WUC0oFcr9SNK"
      },
      "outputs": [],
      "source": [
        "# You code is here"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the results, it is clear that the gap between train and validation accuracy reduces when the number of feature reduces. However, both train, validatin, and test accuracies also decrease."
      ],
      "metadata": {
        "id": "5Bhh4EKZCqaI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 4\n",
        "\n",
        "Let us try to incorporate images from different dates, since crop and tree should have different temporal profile. We will use data from every one. One per month. Here, we will use all spectral bands, and increase the number of training samples to be 10,000 samples per class."
      ],
      "metadata": {
        "id": "1Gw3G_WSDKr5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code to stack all images into a composite one\n",
        "img = ee.ImageCollection('COPERNICUS/S2_SR')\n",
        "img = img.filter(ee.Filter.lt(\"CLOUDY_PIXEL_PERCENTAGE\", 20)).filterBounds(aoi)\n",
        "imstack = None \n",
        "for month in range(1,13):\n",
        "  str_m = f\"{month:02d}\"\n",
        "  date0 = ee.Date(f'2019-{str_m}-01')\n",
        "  date1 = date0.advance(1, \"month\")\n",
        "  img_month = img.filterDate(date0,date1)  \n",
        "  img_month = img_month.select(\"B.*\")#.select([\"B2\", \"B3\", \"B4\", \"B8\"])#.select(\"B.*\")#.select([\"B2\", \"B3\", \"B4\", \"B8\"])\n",
        "  if img_month.size().getInfo() > 0:\n",
        "    print(f\"We have image on Month {month}\")\n",
        "    img_month = img_month.first()\n",
        "    if imstack is None:\n",
        "      imstack = img_month \n",
        "    else:\n",
        "      imstack = imstack.addBands(img_month )\n",
        "\n",
        "imstack = imstack.multiply(0.0001)\n",
        "print(imstack.bandNames().getInfo())"
      ],
      "metadata": {
        "id": "cYGCBG1hDgeQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Take 10,000 samples per classe"
      ],
      "metadata": {
        "id": "_PLjqDu1maw2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample = imstack.addBands(dataset).stratifiedSample(numPoints=10000, \n",
        "                                                    classBand=label,\n",
        "                                                    region=aoi,\n",
        "                                                    scale=10,\n",
        "                                                    geometries=True)"
      ],
      "metadata": {
        "id": "W2PImTIzEQzS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " 70% train 30%Test"
      ],
      "metadata": {
        "id": "8a_IGstSmkNZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample = sample.randomColumn()\n",
        "trainingSample = sample.filter('random <= 0.7')\n",
        "validationSample = sample.filter('random > 0.7')"
      ],
      "metadata": {
        "id": "ZVlji4HgE3Ct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate train, validate and test data"
      ],
      "metadata": {
        "id": "CMdpmFhxmwPh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here\n"
      ],
      "metadata": {
        "id": "4Rn-hb0cE6A-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Work with high resolution Image"
      ],
      "metadata": {
        "id": "1_rzvnyK1Emx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this exercise, we will integrate the unsupervised and supervised classification for LC on high resolution image. "
      ],
      "metadata": {
        "id": "ceXovxAa1fxm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Upload top_mosaic_09cm_area17.tif and gt_top_mosaic_09cm_area17.tif"
      ],
      "metadata": {
        "id": "ndpfWmbyGiu1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Use Gdal library to read both image and ground data"
      ],
      "metadata": {
        "id": "UnOEXjOKHF1r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from osgeo import gdal \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "im = gdal.Open(\"/content/top_mosaic_09cm_area17.tif\")\n",
        "data = im.ReadAsArray().transpose([1,2 ,0])\n",
        "gt = gdal.Open(\"/content/gt_top_mosaic_09cm_area17.tif\")\n",
        "gt_data = gt.ReadAsArray().transpose([1, 2, 0])"
      ],
      "metadata": {
        "id": "hreXSZol1fZ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,7))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(gt_data)\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(data)"
      ],
      "metadata": {
        "id": "sNbtGtsIeW74"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We observe that the class of \"car\" has very limited number of pixels where grass, tress and builds cover the large area."
      ],
      "metadata": {
        "id": "mt6WWE--eexq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Change color in ground data into class lables."
      ],
      "metadata": {
        "id": "E5HnKULLHfuK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(gt_data.reshape(-1,3), axis=0)"
      ],
      "metadata": {
        "id": "jxbtnZIQKZyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "color_dict = {'building':([0,0,255], 0),\n",
        "              'vegetation':([0,255,0], 1),\n",
        "              'grass':([0, 255,255], 2),\n",
        "              'car':([255,255,0],3),\n",
        "              'pavement':([255,255,255],4)}\n"
      ],
      "metadata": {
        "id": "LxIeCLw43ZXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert color ground data into gray-scale image"
      ],
      "metadata": {
        "id": "8j6s5nLmhyDR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_rows, n_cols,_ = gt_data.shape\n",
        "gt_gray = np.zeros((n_rows, n_cols), \"uint8\")\n",
        "color_list = []\n",
        "for k, (name, info) in enumerate(color_dict.items()):\n",
        "  value, label = info\n",
        "  indx = None\n",
        "  color_list.append(value) \n",
        "  for b in range(3):\n",
        "    if indx is None:\n",
        "      indx = (gt_data[:, :, b]==value[b])\n",
        "    else:\n",
        "      indx &= (gt_data[:, :, b]==value[b])\n",
        "  gt_gray[indx] = label\n",
        "color_list = np.array(color_list)\n",
        "plt.figure(figsize=(15,10))\n",
        "plt.imshow(color_list[gt_gray])"
      ],
      "metadata": {
        "id": "BwRSmv4q3bOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. take stratified random samples"
      ],
      "metadata": {
        "id": "JHASFxKGHnRu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def stratifiedRandomSampling(num_samples, image, ground_data):\n",
        "  x = None\n",
        "  y = None\n",
        "  num_classes = ground_data.max() + 1\n",
        "  if image.ndim == 3:\n",
        "    n_rows, n_cols,n_bands = image.shape\n",
        "    im1d = image.reshape((-1, n_bands))\n",
        "  else:\n",
        "    im1d = image\n",
        "  gt1d = ground_data.flatten()\n",
        "  for cls in range(num_classes):\n",
        "    idx = np.nonzero(gt1d==cls)[0]\n",
        "    id_rand = np.random.permutation(idx)[:num_samples]\n",
        "    if x is None:\n",
        "      x = im1d[id_rand,:]\n",
        "      y = np.zeros((len(id_rand),), 'uint8')+ cls\n",
        "    else:\n",
        "      xp = im1d[id_rand,:]\n",
        "      yp = np.zeros((len(id_rand),), 'uint8') + cls\n",
        "      x = np.concatenate((x, xp), axis=0)\n",
        "      y = np.concatenate((y, yp))\n",
        "  idx = np.random.permutation(len(y))\n",
        "  print(x.shape, y.shape)\n",
        "  x = x[idx,:]\n",
        "  y = y[idx]\n",
        "  return x,y  "
      ],
      "metadata": {
        "id": "E8jdeDzi3x1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### obtain 500 samples per class"
      ],
      "metadata": {
        "id": "4p0EF4-PHtha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x,y = stratifiedRandomSampling(num_samples=500, image=data, ground_data=gt_gray)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3s9aKS-7_HD",
        "outputId": "23030196-6e6c-436b-ccf9-b388acb3be0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2500, 3) (2500,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. make train and test sample using sklearn library"
      ],
      "metadata": {
        "id": "vNeW1UBsHxpk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)"
      ],
      "metadata": {
        "id": "Onb5i3z38ySG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Perform pixel-wise classificaiton using Random Forest classifier with 200 trees with maximum depth of 5."
      ],
      "metadata": {
        "id": "63sVpZv2IGbw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "clf = RandomForestClassifier(n_estimators=200, max_depth=5, random_state=0)\n",
        "clf.fit(x_train, y_train)\n",
        "print(f\"Train Accuracy: {clf.score(x_train, y_train):0.3f}\")\n",
        "print(f\"Test Accuracy: {clf.score(x_test, y_test):0.3f}\")"
      ],
      "metadata": {
        "id": "m4aYxuci8nM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the accuracy result, the classifier is overfitted!!!"
      ],
      "metadata": {
        "id": "l4qojj4JIs40"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. perform land cover mapping on the entire scene"
      ],
      "metadata": {
        "id": "305_Cy47Iytx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data1d = data.reshape(-1,3)\n",
        "lc_map = clf.predict(data1d)\n",
        "lc_map = lc_map.reshape(n_rows, n_cols)"
      ],
      "metadata": {
        "id": "kxEdpvPVCJRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Display the result"
      ],
      "metadata": {
        "id": "UNkfzBsKI4JA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,10))\n",
        "plt.imshow(color_list[lc_map])"
      ],
      "metadata": {
        "id": "92EpX0P1CUxc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Evaluate the peformance"
      ],
      "metadata": {
        "id": "xrrvFEzMJGp6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "legend_high_res = list(color_dict.keys())"
      ],
      "metadata": {
        "id": "XD33Z9Cbffbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "conf_train = confusion_matrix(y_train, clf.predict(x_train))\n",
        "conf_valid = confusion_matrix(y_test, clf.predict(x_test))\n",
        "conf_whole =  confusion_matrix(gt_gray.flatten(), lc_map.flatten())\n",
        "legend_high_res = list(color_dict.keys())\n",
        "print(\"TRAIN SAMPLES\")\n",
        "_ = evaluteReport(conf_train, legend_high_res)\n",
        "print(\"TEST SAMPLES\")\n",
        "_ = evaluteReport(conf_valid, legend_high_res)\n",
        "print(\"WHOLE IMAGE\")\n",
        "_ = evaluteReport(conf_whole, legend_high_res)"
      ],
      "metadata": {
        "id": "y1ltbeDhJKkk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 10. Let us integrate the clustering algorithm with the supervised classification by performning superpixel clustering using SEEDS algorithm for $N=1000$ super-pixels."
      ],
      "metadata": {
        "id": "ngjkTmplL0Yz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 \n",
        "num_pixels = data.shape[0]  * data.shape[1]\n",
        "num_sub_pixels = 1000\n",
        "seeds = cv2.ximgproc.createSuperpixelSEEDS(data.shape[1], \n",
        "                                           data.shape[0], \n",
        "                                           data.shape[2],\n",
        "                                           num_superpixels=num_sub_pixels,\n",
        "                                           num_levels=5)\n",
        "\n",
        "seeds.iterate(data, 500)\n",
        "mask = seeds.getLabelContourMask(thick_line=True)\n",
        "mask = mask[:,:,np.newaxis]\n",
        "dat2 = (mask==255)*np.array([[0,255,255]]) + (mask==0)*data\n",
        "plt.figure(figsize=(15,10))\n",
        "plt.imshow(dat2)\n",
        "plt.title(f\"K={num_sub_pixels}\")"
      ],
      "metadata": {
        "id": "OH3Fk1-H9Enh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 11. Obtain superpixel lables"
      ],
      "metadata": {
        "id": "AnCvWheVMX7t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spxl_im = seeds.getLabels()\n",
        "print(np.unique(spxl_im))"
      ],
      "metadata": {
        "id": "QL6bmssN9w5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 12. Convert superpixel into feature vector. Here, we extract band-wise mean and standard deviation. For one superpixel, we have 6 values (3 for means and 3 for standard deviation"
      ],
      "metadata": {
        "id": "b8kaV-uLMk1c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "spxl_im1d = spxl_im.flatten()\n",
        "data1d = data.reshape(-1,3)\n",
        "gt_gray_1d = gt_gray.flatten()\n",
        "features =[]\n",
        "spxl_labels = []\n",
        "for val in np.unique(spxl_im1d):\n",
        "  patch = data1d[spxl_im1d==val,:]\n",
        "  lb_patch = gt_gray_1d[spxl_im1d==val]\n",
        "  mode = stats.mode(lb_patch)\n",
        "  spxl_labels.append(mode[0][0])\n",
        "  #ft = [np.concatenate((patch.mean(0), patch.std(0)))]\n",
        "  ft= patch.mean(0)\n",
        "  features.append(ft)\n",
        "features = np.array(features).reshape(-1,3)\n",
        "spxl_labels = np.array(spxl_labels)"
      ],
      "metadata": {
        "id": "So8iIaXT-RAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 13. Due to limited number of super pixels, we use 20% for train and 80% for test"
      ],
      "metadata": {
        "id": "1XakrGbjM6ny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xsp,ysp = stratifiedRandomSampling(num_samples=20, image=features, ground_data=spxl_labels)"
      ],
      "metadata": {
        "id": "lQkRasa6Tkig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 14. Here, we employed the k-nearest neighbors with neighbor size of 7."
      ],
      "metadata": {
        "id": "9c1UbVQiNIJI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knnmodel = KNeighborsClassifier(n_neighbors=7)\n",
        "knnmodel.fit(xsp, ysp)"
      ],
      "metadata": {
        "id": "_PhWvz6W-Tvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 15. Perform classification on superpixels and put the labels into the image"
      ],
      "metadata": {
        "id": "y5-EnXZ7Nb_1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sp_map = knnmodel.predict(features)\n",
        "lc_map2 = np.zeros((n_rows, n_cols), 'uint8')\n",
        "for k,val in enumerate(np.unique(spxl_im1d)):\n",
        "  lc_map2[spxl_im==val] = sp_map[k]\n",
        "plt.figure(figsize=(15,10))\n",
        "plt.imshow(color_list[lc_map2])"
      ],
      "metadata": {
        "id": "frEIxVUUBfSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 16. Compare between different approaches"
      ],
      "metadata": {
        "id": "R3Pe1dtNNlu8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,10))\n",
        "plt.subplot(2,2,1)\n",
        "plt.imshow(color_list[gt_gray])\n",
        "plt.title(\"Ground Data\")\n",
        "plt.subplot(2,2,2)\n",
        "plt.imshow(color_list[lc_map])\n",
        "plt.title(\"Pixel-wise classification\")\n",
        "plt.subplot(2,2,3)\n",
        "plt.imshow(color_list[lc_map2])\n",
        "plt.title(\"Superpixel Classification\")"
      ],
      "metadata": {
        "id": "WTUbfYEnDhBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 5\n",
        "Compare the accuracies (Overall, User's, Producers' accuracies) of superpixel classification againts pixelwise approach. Which one is better?"
      ],
      "metadata": {
        "id": "LfCUzlNUOCxD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code"
      ],
      "metadata": {
        "id": "XJSJntmFDzIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 6\n",
        "Repeat the superpixel classification with $N=10,000$ superpixels with 250 training pixels per class.\n",
        "\n",
        "Between $N=1,000$ and $N=10,000$ super-pixels which one perform better?"
      ],
      "metadata": {
        "id": "wL9-zqglkWrP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code"
      ],
      "metadata": {
        "id": "09EG9S_dkoSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 7\n",
        "Repeat the superpixel classification with $N=10,000$ superpixels with 250 training pixels per class with Random Forest Classifier with the same parameter with pixelwise.\n",
        "\n",
        "Compare between K-nearest neighbor and Random Forest. Which one has higer accuracy?"
      ],
      "metadata": {
        "id": "JSMBk1OLkqro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code"
      ],
      "metadata": {
        "id": "IgLoW3mdkqJn"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": " WorkShopImageClassification.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNFsWuU/4NP+1cgkcGm1bbX",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}